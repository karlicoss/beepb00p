#!/usr/bin/env python3
from __future__ import annotations

from concurrent.futures import Executor
import json
from pathlib import Path
import re
from typing import Tuple, Iterable

import click
import bs4  # type: ignore[import]
from more_itertools import divide


File = str
Id = str
Text = str


def walk(node) -> Iterable[Tuple[Id, Text]]:
    id_ = node.get('id')
    if id_ in {
        'table-of-contents',
        'jumptosidebar',
        'exobrain-toc',
        'sidebar',
    }:
        node.decompose()
        return

    cs = list(node.find_all(recursive=False))
    # FIXME kinda annoying that headerlink points at h2, not the enclosing container?
    # on the other hand I guess makes more sense to get the 'closest' link rather than the actually enclosing?
    for c in cs:
        yield from walk(c)

    if id_ is not None:
        text = node.text
        text = re.sub(r'\n+', '\n', text).strip()
        if len(text) > 0:
            yield (id_, text)
        node.decompose() # prevent from being processed by the parent


def walk_batch(htmls: list[Path], root: Path):
    ress = []
    for html in htmls:
        if html.name == 'sitemap.html':
            continue
        import warnings
        warnings.filterwarnings('ignore', category=bs4.XMLParsedAsHTMLWarning)
        soup = bs4.BeautifulSoup(html.read_text(), 'lxml').find('body')
        rpath = html.relative_to(root)
        for key, res in walk(soup):
            ress.append((str(rpath), key, res))
    return ress


def walk_all(*, root: Path, pool: Executor) -> Iterable[Tuple[File, Id, Text]]:
    htmls = sorted(root.rglob('*.html'))
    assert len(htmls) > 0, root

    workers = pool._max_workers  # type: ignore[attr-defined]
    groups = [list(group) for group in divide(workers, htmls)]
    futures = [pool.submit(walk_batch, group, root) for group in groups]
    for group, fut in zip(groups, futures):
        try:
            yield from fut.result()
        except Exception as e:
            raise RuntimeError(f'error while processing {group}') from e


def make_index(*, root: Path, pool: Executor) -> str:
    documents = [{
        'file': file,
        'id'  : id,
        'text': text,
    } for file, id, text in walk_all(root=root, pool=pool)]
    return f'''
/* AUTOGENERATED by makeindex.py */
let documents = {json.dumps(documents, indent=1, ensure_ascii=False)}
'''.lstrip()


@click.command()
@click.option('--root', type=Path, required=True)
def main(root: Path) -> None:
    print(make_index(root=root, pool=None))  # type: ignore[arg-type]


if __name__ == '__main__':
    main()
