#!/usr/bin/env python3
"""
Render referrers as a HTML table so I can see where my stuff is posted.
"""
from datetime import timedelta, datetime
from itertools import islice
from pathlib import Path
from pprint import pprint
import re
import sys
from time import sleep
from typing import Set, Dict, Any, Optional

import pandas as pd # type: ignore


from logs.common import get_delta, get_delta_sql


# -1 for infinite
# TODO percentile??

import logging
logger = logging.getLogger('referers')


less_prio = {
    'reddit.com',
    'lobste.rs',
    'news.ycombinator.com',
    # TODO add other hn readers? or keep in external config
}


from typing import Iterable, Tuple
Timestamp = datetime
Page = str
Referer = str

Row = Tuple[Timestamp, Page, Referer]


_BORING = {
    '/rss.xml'    ,
    '/atom.xml'   ,
    '/favicon.ico',
    '/robots.txt' ,
    '/apple-touch-icon.png',
    '/apple-touch-icon-precomposed.png',
    '/exobrain/searchindex.json',
    # todo UGH. get rid of this font..
    '/exobrain/FontAwesome/fonts/fontawesome-webfont.woff2?v=4.7.0',
    # todo ugh
    '/notset',
}

def iter_log(access_log: Path, delta: Optional[timedelta]=None) -> Iterable[Row]:
    import sqlite3

    BQ = 'page NOT IN (' + ', '.join(f'"{x}"' for x in _BORING) + ')'

    LQ = get_delta_sql(delta)

    # TODO ugh, not sure why stuff like "/./tags.html" ends up in logs??
    normalise_page = 'REPLACE(page, "./", "")'
    conn = sqlite3.connect(f'file:{access_log}?immutable=1', uri=True)
    with conn:
        # 'now'
        res = conn.execute(f'''
SELECT timestamp, {normalise_page}, referer
FROM visits
WHERE
     {BQ}
 AND page NOT LIKE '/css/%'
 AND page NOT LIKE '%.css'
 AND page NOT LIKE '%.js'
 AND page NOT LIKE '/comments/%'
 AND page NOT LIKE '%.svg'
 AND page NOT LIKE '%robot-face%'
 AND referer NOT LIKE 'https://beepb00p.xyz%'
     {LQ}
ORDER BY timestamp DESC
''')
# todo not sure about excluding beepb00p.xyz here?
        for ts, page, referer in res:
            # todo not sure which timezone to use?
            dt = datetime.utcfromtimestamp(ts)
            yield (dt, page, referer)



def run(*, access_log: Path, exclude: Optional[Path]=None, delta: Optional[timedelta]=None):
    excluded: Set[str] = set()
    if exclude is not None:
        res: Dict[str, Any] = {}
        logger.info('loading excludes from: %s', exclude)
        exec(exclude.read_text(), res)
        excl = res['EXCLUDE']
        for e in excl:
            lines = e.splitlines()
            lines = (l.strip() for l in lines if len(l.strip()) > 0)
            excluded.update(lines)
        # TODO maybe these excludes should be paired with URLS?
        logger.info('loaded %d excludes', len(excluded))
        pprint(list(sorted(excluded)), stream=sys.stderr)

    pd.set_option('display.max_colwidth', 200)

    # meh
    EXCLUDED_RE = re.compile('|'.join(e for e in excluded)) if len(excluded) > 0 else None

    # TODO not sure if should use pandas?

    def is_boring(row: Row) -> bool:
        url = row[1]
        if url is None:
            return True

        # TODO filter reddit/hn somehow? or just sort to display in the bottom?
        ref = row[2]
        if EXCLUDED_RE is not None and EXCLUDED_RE.search(ref):
            return True
        return False

    cols = ('dt', 'page', 'referer')


    total = 0
    def it():
        nonlocal total
        for row in iter_log(access_log=access_log, delta=delta):
            total += 1
            # TODO add it to the query? not sure
            if not is_boring(row):
                yield row

    df = pd.DataFrame(it(), columns=cols) #  + ['error'])
    logger.info('dataframe: %d non-boring lines (total %d)', len(df), total)
    # df = df[~df['error'].notnull()] # TODO not sure if makes more sense to filter straightaway...
    logger.info('after filtering errors: %d lines', len(df))

    # TODO dynamic sorting for pandas would be nice?
    # df = df.sort_values(by=[
    #     # 'refferer',
    #     'dt',
    # ], ascending=False)[[
    #     'dt',
    #     'page',
    #     'referer',
    # ]]

    gc = df.groupby(['page', 'referer']).count()
    # todo also quantile?
    gc = gc[gc['dt'] >= 5]
    gc = gc.sort_values(by=['dt'])

    # we don't want them to display in the detailed log
    df = df[df['referer'] != '']

    return df, gc


def main():
    import argparse
    p = argparse.ArgumentParser()
    p.add_argument('--access-log', type=Path, required=True, help='log sqlite database')
    p.add_argument('--html', type=Path)
    p.add_argument('--exclude', type=Path)
    p.add_argument('--last', type=str, help='example: 3d or 10h')
    args = p.parse_args()
    html = args.html

    # TODO fix last in crontabs

    delta = get_delta(args.last)

    rt, gcount  = run(access_log=args.access_log, exclude=args.exclude, delta=delta)

    logger.info('rendering...')
    # TODO ugh. need some wort of iterative html rendering.. it takes 10% memeory as well
    if html is not None:
        with html.open('w') as fo:
            fo.write('''
            <html>
            <head>
                <script src="https://cdn.jsdelivr.net/npm/sorttable@1.0.2/sorttable.min.js"></script>
                <style>
                /* col0: dt, col1, col2: url, referrers. meh, but works */
                td.col0 { white-space: nowrap; }
                td.col1,td.col2 { word-break: break-all; }
                </style>
            </head>
            <body>
            '''.strip())

            rt['referer'] = rt['referer'].map(lambda u: f'<a href="{u}">{u}</a>')

            refs = rt['referer'].value_counts()

            # print(refs.quantile(axis='columns')) # 0.1))
            q90 = refs.quantile(0.90)
            print(f'90th quantile: {q90} visits')
            # TODO FIXME percentile??
            def style(ser):
                if ser.name != 'referer':
                    return ['' for _ in ser]
                else:
                    return ['font-weight:bold' if refs[val] < q90 else ''  for _, val in ser.items()]

            rt['dt'] = rt['dt'].dt.strftime('%Y-%m-%d %H:%M')

            rts = rt.style.apply(style).render()
            # rts = rt.to_html()
            # rts = rts.replace('class="dataframe"', 'class="dataframe sortable"')
            rts = rts.replace('<table ', '<table border=1 class="dataframe sortable"')
            # detailed
            fo.write(rts)

            gc = gcount.to_html().replace('class="dataframe"', 'class="dataframe sortable"')
            # breakdown for each post + referrer
            fo.write(gc)

            rf = refs.to_frame()
            rf = rf[rf.referer > q90]
            print(rf)
            # total stats across all referrers
            fo.write(rf.to_html())

            fo.write('</body></html>')
    else:
        print(rt)
        print(gcount)
    logger.info('total lines: %d', len(rt))


if __name__ == '__main__':
    main()
